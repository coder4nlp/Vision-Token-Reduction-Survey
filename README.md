# Vision-Token-Reduction-Survey
> A Comprehensive Survey and Resource Collection of Vision Token Reduction Techniques for Multimodal Large Models

# 📌 Project Overview
With the explosive growth of multimodal large models (such as LLaVA, Flamingo, BLIP-2, Qwen-VL), **efficient reduction of visual tokens** has become a key technology for reducing computational costs and enhancing inference speed. This repository systematically collects, analyzes, and compares the cutting-edge methods and advancements in the field of visual token compression.

**Core Value**: Enable researchers to quickly grasp the progress in the field.

# 🗂️ 仓库结构
```
Vision-Token-Reduction-Survey
├── papers_summaries/ 
├── methods_comparison/ 
├── datasets/ 
├── tech_reports_blogposts/ 
├── resources/ 
├── CONTRIBUTING.md
└── README.md 
```

| Paper Title | One-sentence Abstract | Date | Conference    |
|-|-|-|-|
| *VScan: Rethinking Visual Token Reduction for Efficient Large Vision-Language Models* [PDF](https://arxiv.org/pdf/2505.22654v1)| This work proposes VScan, a two-stage visual token reduction framework for large vision-language models (LVLMs), achieving significant inference acceleration (2.91× speedup in prefilling, 10× FLOPs reduction) with minimal performance loss (95.4% retention) through complementary global/local token merging and intermediate-layer pruning. | 202505| arXiv (preprint)    | December |
| *Less is More: A Simple yet Effective Token Reduction Method for Efficient Multi-modal LLMs* [PDF](https://arxiv.org/pdf/2409.10994)| TRIM (Token Reduction using CLIP Metric) enhances Multimodal Large Language Models (MLLMs) efficiency by reducing image tokens without performance loss, validated across 12 datasets, advancing sustainable high-performance model development.  | 202409| COLING 2025| 

