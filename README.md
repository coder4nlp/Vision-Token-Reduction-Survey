# Vision-Token-Reduction-Survey
> A Comprehensive Survey and Resource Collection of Vision Token Reduction Techniques for Multimodal Large Models

# ğŸ“Œ Project Overview
With the explosive growth of multimodal large models (such as LLaVA, Flamingo, BLIP-2, Qwen-VL), **efficient reduction of visual tokens** has become a key technology for reducing computational costs and enhancing inference speed. This repository systematically collects, analyzes, and compares the cutting-edge methods and advancements in the field of visual token compression.

**Core Value**: Enable researchers to quickly grasp the progress in the field.

# ğŸ—‚ï¸ ä»“åº“ç»“æ„
```
Vision-Token-Reduction-Survey
â”œâ”€â”€ papers_summaries/ 
â”œâ”€â”€ methods_comparison/ 
â”œâ”€â”€ datasets/ 
â”œâ”€â”€ tech_reports_blogposts/ 
â”œâ”€â”€ resources/ 
â”œâ”€â”€ CONTRIBUTING.md
â””â”€â”€ README.md 
```

| Paper Title | One-sentence Abstract | Date | Conference    |
|-|-|-|-|
| *VScan: Rethinking Visual Token Reduction for Efficient Large Vision-Language Models* [PDF](https://arxiv.org/pdf/2505.22654v1)| This work proposes VScan, a two-stage visual token reduction framework for large vision-language models (LVLMs), achieving significant inference acceleration (2.91Ã— speedup in prefilling, 10Ã— FLOPs reduction) with minimal performance loss (95.4% retention) through complementary global/local token merging and intermediate-layer pruning. | 202505| arXiv (preprint)    | December |
| *Less is More: A Simple yet Effective Token Reduction Method for Efficient Multi-modal LLMs* [PDF](https://arxiv.org/pdf/2409.10994)| TRIM (Token Reduction using CLIP Metric) enhances Multimodal Large Language Models (MLLMs) efficiency by reducing image tokens without performance loss, validated across 12 datasets, advancing sustainable high-performance model development.  | 202409| COLING 2025| 

