PACT由三个步骤组成：
* 不重要的token识别
* 其余token聚类
* 合并每个类中的token，以及最初被舍弃但距离足够近的标记将被合并

PACT在语言模型的选定层L内操作，适用于将可视标记输入语言模型的场景，而不管可视编码器或连接器的体系结构如何。
层L的隐状态为$H \in R^{n \times d}$，$n$是视觉token的个数，d是隐状态的维度。$K,Q \in R^{n \times n_h\times d_h}$是视觉token的key和query矩阵。$n_h$表示注意力的头数，$d_h$是每个注意力头的维度。为了简便起见，我们在符号中省略了层索引。
我们用下标来表示一个标记的位置索引，而注意力头则用上标来表示。
例如，$k_i^j$表示与第$i$个视觉token的第$j$个注意力头相对应的key向量。

## 不重要token识别
一种直接的方法来识别所用语言模型中某一层$L$的不重要标记，是将每个token的重要性定义为该token从所有其他token处获得的总注意力得分。这个方法由三个注意的问题：
* 当前的利用FlashAttention的VLMs不支持输出注意力得分。
* 注意力分数是通过掩码计算得出的，这会引入偏差。
* 序列末尾的token往往平均注意力得分较低，因为关注它们的标记较少。仅基于关注每个标记的标记来计算其平均注意力得分可以减轻这种掩蔽效应，但会引入新的偏差：序列末尾的标记可能会表现出较高的得分，因为它们主要受到附近标记的关注。应该避免这种位置偏差，因为修剪应该完全依赖于视觉标记所包含的信息，而不是它们的位置。最后，仅仅依靠单一层次的键值和查询来确定重要性指标可能会无法完全捕捉到语言模型所有层中视觉标记的真正重要性，这主要是因为每个自注意力层关注的是视觉标记的不同方面。

为了解决以上问题，我们提出了一种重要性度量方法，该方法将早期层L中隐藏状态的累积信息以及键和查询的层特定信息结合在一起。我们将这种方法称为“高效不重要token识别”（Efficient Unimportant Tokens Identification, EUTI）。我们推测，隐藏状态的范数能够提供有关每个视觉标记重要性的关键信息，因为它们反映了特定标记在网络中所承载的信息量。图 3 展示了 LLaVA-OneVision-7B 第四层视觉标记的隐藏状态规范的统计数据，表明其具有较高的方差。
![](llava-onevision-7b-norm.PNG1)


为了利用来自隐藏状态规范以及关键和查询向量的信息，我们首先计算一个全局查询向量 $Q_{global}$，其值为所有视觉标记下的查询向量的平均值：
$$
Q_{global}=\frac {1}{n} \sum_{i=1}^nQ_i
$$

这个向量表示了在第L层的所有注意力头中，由视觉token所请求的总体query信息。每个视觉标记的重要性分数然后通过首先取其query和每个注意头的全局query之间的点积来计算。
$$
s_i=\frac {1}{n_h}\sum_{j=1}^{n_h}softmax(k_i^{j} Q_{global}^{j})||h_i||_2
$$
在每个注意力头内，会对视觉token应用softmax操作，然后对各个注意力头的结果进行平均处理。最终得分是通过将结果乘以隐藏状态的范数来获得的。


然后，使用一个参数$\$将视觉token划分为重要和不重要的token，
$$
S_{important}={i|s_i \ge Percentile(s,)}
$$