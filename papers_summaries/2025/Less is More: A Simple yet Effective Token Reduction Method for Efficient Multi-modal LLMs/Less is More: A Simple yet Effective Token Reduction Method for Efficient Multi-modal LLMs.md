# 1 研究背景
**1. 研究问题**: 这篇文章要解决的问题是多模态大语言模型（MLLMs）在性能提升的同时，资源消耗显著增加的问题。具体来说，随着MLLMs的发展，它们在处理高分辨率图像和视频时需要大量的计算和内存资源。

**2.研究难点**: 该问题的研究难点包括如何在减少计算和内存需求的同时，保持模型的性能不下降。现有的方法如轻量化架构和专用组件优化虽然在一定程度上缓解了这一问题，但在多模态场景下仍存在挑战。

**3. 相关工作**: 相关工作包括早期的视觉信息投影方法、固定长度视觉标记压缩方法和最近的LLaVA架构简化方法。然而，这些方法在MLLMs中的应用还不够紧密或高效。

# 2 研究方法

这篇论文提出了名为Token Reduction using CLIP Metric（TRIM）的方法，用于解决MLLMs中的图像标记减少问题。具体来说，TRIM方法利用CLIP模型的相似性度量来评估图像标记的重要性，并通过自适应选择关键标记来减少计算和内存开销。

**1. CLIP相似性度量**: TRIM方法首先利用CLIP模型计算的文本和图像块之间的相似性来评估每个图像标记的重要性。公式如下：

$$
S(v_{i},u_{pooled}) = \frac{v_{i} \cdot u_{pooled}}{\Vert v_{i}\Vert \Vert u_{pooled}\Vert}
$$   


   其中，$v_{i}$表示图像标记，$u_{pooled}$是从CLIP的`[eot]`标记中提取的池化文本表示。

**2. 自适应选择关键标记**: 为了确定保留的最佳图像标记数量，TRIM方法采用四分位距（`IQR`）方法。`IQ`R计算为相似性分数的上四分位数（Q3）和下四分位数（Q1）之间的差异，并用于确定严格的选择阈值$Q3+1.5\times IQR$。

**3. 聚合未选择的标记**: 为了保留未选择的图像标记中的信息，TRIM方法计算这些标记的平均表示，并将其作为聚合标记附加到选择的标记序列中。公式如下：

   
$$
   Z_{v, p}^{\prime} = \frac{1}{N}\sum_{i=1}^{N} z_{v,i}   
$$
   其中，$z_{v,i}$表示未选择的图像标记的表示。



# 3 实验设计

实验设计遵循LLaVA 1.5的设置，主要区别在于在指令微调阶段仅使用TRIM方法。实验在12个不同的数据集上进行，评估结果与5种最先进的MLLMs和一种相关方法进行比较。

**1.数据集**: 实验使用了12个不同的数据集，包括VQA-v2、GQA、VisWiz、SQAI、VQAT、POPE、MME、MMB、SEED1、LLaVA-Bench和MM-Vet。

**2.训练和评估设置**: 训练数据集包括LLaVA、ShareGPT、VQAv2、GQA、OKVQA、OCR-VQA、A-OKVQA、TextCaps、RefCOCO、VG等，总共有665K个样本。训练超参数包括批量大小128、学习率2e-5、余弦衰减学习率调度、权重衰减0等。

# 4 结果与分析

实验结果表明，TRIM方法在减少计算开销的同时保持了与基线模型相当的性能。
* **性能保持**: 尽管图像标记数量减少到21%，TRIM方法在12个数据集上的性能仍然与LLaVA-1.5相当，甚至在SQAI和MMB数据集上超过了基线模型。

* **计算效率**: TRIM方法显著加速了模型推理速度并减少了内存使用。具体来说，生成第一个标记的时间缩短到原来的32.9%，内存使用减少了30%。

* **消融研究**: 消融研究表明，TRIM方法中的自动图像标记选择策略和聚合标记策略对性能提升有显著贡献。

* **跨分辨率有效性** : 在不同分辨率下的实验表明，TRIM方法在不同分辨率下均能有效保持性能。

* **视频基准测试**: 在MSVD-QA和MSRVTT-QA视频基准测试中，TRIM方法显著减少了生成第一个标记的时间，同时保持了相当的准确性和平均分数。



总体结论

这篇论文提出了TRIM方法，通过在MLLMs中减少图像标记数量来提高效率，同时保持模型性能。TRIM方法利用CLIP模型的相似性度量和自适应选择策略，显著减少了计算和内存开销。实验结果表明，TRIM方法在多个数据集和任务上均表现出色，为资源高效的MLLMs发展迈出了重要一步。未来的工作将进一步整合TRIM方法到更多样化的模型和视觉编码器中。